# https://docs.microsoft.com/azure/devops/pipelines/languages/php

trigger:
  branches:
    include:
      - master
      - gdb # TODO: Remove

pool:
  vmImage: ubuntu-18.04

variables:
  phpVersion: 7.3
  chunks: 6
  test: 1 # TODO: Remove

jobs:
- job: Initialize
  steps:
  - template: system.yml

  - script: 250 applist > applist.json
    displayName: Download app list
    workingDirectory: $(BUILDDIR)

#  - script: PATREON_API_KEY=$(PATREON_API_KEY) 250 patron-import
#    displayName: Import patron reviews
#    workingDirectory: $(BUILDDIR)

#  - script: 250 players-import
#    displayName: Import player stats
#    workingDirectory: $(BUILDDIR)

  - script: data upload "$BUILDDIR" "$RBUILDDIR"
    displayName: Upload build artifacts

- job: Import
  dependsOn: Initialize
  strategy:
    parallel: $[variables['chunks']]
  steps:
  - template: system.yml

  - script: dig +short myip.opendns.com @resolver1.opendns.com
    displayName: WAN IP

  - script: sudo apt install --assume-yes gdb
    displayName: Install GDB

  - script: |
      echo "
        set pagination off
        set logging file gdb.$AZURE_BUILD_NUMBER.$(System.JobPositionInPhase).txt
        set logging on
        set \$_exitcode = -999
        handle SIGTERM nostop print pass
        handle SIGPIPE nostop noprint pass
        define hook-stop
            if \$_exitcode != -999
                echo normal exit\n
                quit
            else
                echo abnormal exit\n
                bt
                quit
            end
        end
        run
      " > gdb.script

      USE_ZEND_ALLOC=0 gdb --batch --command=gdb.script -return-child-result --args \
        php -dzend.assertions=1 "$(Build.SourcesDirectory)/bin/250" -v import-async --lite \
          --chunks $(System.TotalJobsInPhase) -i $(System.JobPositionInPhase) \
          --steam-spy "$(Build.SourcesDirectory)/data/steamspy 20180411.json" applist.json
    displayName: Import apps ($(System.JobPositionInPhase)/$(System.TotalJobsInPhase))
    workingDirectory: $(BUILDDIR)
    env:
      AMP_LOG_TIMER_QUEUE_PATH: $(BUILDDIR)/tq-$(System.JobPositionInPhase).log

  - script: retry data upload "$BUILDDIR" "$RBUILDDIR"
    displayName: Upload build artifacts
    condition: succeededOrFailed() # Upload core dump when task failed but not if job cancelled.

- job: Stitch
  dependsOn: Import
  steps:
  - template: system.yml

  - script: 250 stitch "$(BUILDDIR)"
    displayName: Stitch

  - script: |
      data upload "$BUILDDIR" "$RBUILDDIR" &&
      data delete "$RBUILDDIR" -p '\.p\d\d?$' &&
      data move "$RBUILDDIR" &&
      data delete $MARKER
    displayName: Upload build artifacts and clean up
    condition: not(variables.test)

  - script: |
      [[ '$(Build.Reason)' = Schedule ]] &&
        TRAVIS_TOKEN='$(TRAVIS_CRON_API_KEY)' ||
        TRAVIS_TOKEN='$(TRAVIS_API_KEY)'

      curl -sSf\
        -H 'Travis-API-Version: 3'\
        -H "Authorization: token $TRAVIS_TOKEN"\
        -H 'Content-Type: application/json'\
        -d '{"request": {"branch": "master"}}'\
        https://api.travis-ci.org/repo/250%2FSteam-250/requests
    displayName: Trigger Steam 250 repository build
    condition: not(variables.test)

  - script: |
      set -v
      retry data download-last2
      wget --progress=dot:mega\
        https://github.com/aktau/github-release/releases/download/v0.7.2/linux-amd64-github-release.tar.bz2
      tar xvf *.tar.* --xform 's#.*/##'
      rm -v *.tar.*
      tar cJvf tar *.*
      ./github-release upload --user 250 --repo Steam-250 --tag snapshots --name snapshots.tar.xz --file tar --replace\
        --security-token '$(GITHUB_AZURE_TOKEN)'
    displayName: Upload snapshots
    workingDirectory: $(Build.ArtifactStagingDirectory)
    condition: not(variables.test)
